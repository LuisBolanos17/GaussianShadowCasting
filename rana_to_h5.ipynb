{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
    "from smplx import SMPL\n",
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "np.float = float\n",
    "np.int = int\n",
    "import glob\n",
    "import skvideo.io\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import wget\n",
    "import requests\n",
    "import io\n",
    "\n",
    "from core.datasets.preprocess.process_spin import SMPL_JOINT_MAPPER, write_to_h5py\n",
    "from core.utils.skeleton_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.bool = bool\n",
    "np.complex = complex\n",
    "np.object = object\n",
    "np.unicode = None\n",
    "np.str = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_rest_pose = np.array([[ 0.00000000e+00,  2.30003661e-09, -9.86228770e-08],\n",
    "                           [ 1.63832515e-01, -2.17391014e-01, -2.89178602e-02],\n",
    "                           [-1.57855421e-01, -2.14761734e-01, -2.09642015e-02],\n",
    "                           [-7.04505108e-03,  2.50450850e-01, -4.11837511e-02],\n",
    "                           [ 2.42021069e-01, -1.08830070e+00, -3.14962119e-02],\n",
    "                           [-2.47206554e-01, -1.10715497e+00, -3.06970738e-02],\n",
    "                           [ 3.95125849e-03,  5.94849110e-01, -4.03754264e-02],\n",
    "                           [ 2.12680623e-01, -1.99382353e+00, -1.29327580e-01],\n",
    "                           [-2.10857525e-01, -2.01218796e+00, -1.23002514e-01],\n",
    "                           [ 9.39484313e-03,  7.19204426e-01,  2.06931755e-02],\n",
    "                           [ 2.63385147e-01, -2.12222481e+00,  1.46775618e-01],\n",
    "                           [-2.51970559e-01, -2.12153077e+00,  1.60450473e-01],\n",
    "                           [ 3.83779174e-03,  1.22592449e+00, -9.78838727e-02],\n",
    "                           [ 1.91201791e-01,  1.00385976e+00, -6.21964522e-02],\n",
    "                           [-1.77145526e-01,  9.96228695e-01, -7.55542740e-02],\n",
    "                           [ 1.68482102e-02,  1.38698268e+00,  2.44048554e-02],\n",
    "                           [ 4.01985168e-01,  1.07928419e+00, -7.47655183e-02],\n",
    "                           [-3.98825467e-01,  1.07523870e+00, -9.96334553e-02],\n",
    "                           [ 1.00236952e+00,  1.05217218e+00, -1.35129794e-01],\n",
    "                           [-9.86728609e-01,  1.04515052e+00, -1.40235111e-01],\n",
    "                           [ 1.56646240e+00,  1.06961894e+00, -1.37338534e-01],\n",
    "                           [-1.56946480e+00,  1.05935931e+00, -1.53905824e-01],\n",
    "                           [ 1.75282109e+00,  1.04682994e+00, -1.68231070e-01],\n",
    "                           [-1.75758195e+00,  1.04255080e+00, -1.77773550e-01]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_RANA(subject_folder):\n",
    "    json_files = sorted(glob.glob(os.path.join(subject_folder, '*.json')))\n",
    "    img_paths = sorted(glob.glob(os.path.join(subject_folder, '*[0-9].png')))\n",
    "    mask_paths = sorted(glob.glob(os.path.join(subject_folder, '*semantic.png')))\n",
    "    num_frames = len(json_files)\n",
    "    print('number of frames:', num_frames)\n",
    "    print(json_files)\n",
    "    print(img_paths)\n",
    "    print(mask_paths)\n",
    "\n",
    "\n",
    "    #################################################################### INDICES #######################################################################\n",
    "    cam_idxs = np.zeros(num_frames) # maps from image idx to camera idx (they all use the same camera with idx 0)\n",
    "    kp_idxs = np.arange(num_frames) # maps from image idx to pose idx (monocular data so just arange num frames)\n",
    "\n",
    "    ################################################################## CAMERA STUFF #####################################################################\n",
    "    temp_data = json.load(open(json_files[0]))['skeleton_0']['smpl_data']\n",
    "    W = 1280\n",
    "    H = 720\n",
    "    \n",
    "    K = []\n",
    "    focals = []\n",
    "    centers = []\n",
    "    c2ws = []\n",
    "\n",
    "    # for camera in camera_names:\n",
    "    K.append(np.array(temp_data['K']))\n",
    "    focals.append([K[-1][0, 0], K[-1][1, 1]])\n",
    "    centers.append([K[-1][0, 2], K[-1][1, 2]])\n",
    "    ext = np.eye(4)\n",
    "    c2w = np.linalg.inv(ext)\n",
    "    c2w = swap_mat(c2w)\n",
    "    c2ws.append(c2w)\n",
    "\n",
    "    K = np.stack(K)\n",
    "    focals = np.stack(focals)\n",
    "    centers = np.stack(centers)\n",
    "    c2ws = np.stack(c2ws)\n",
    "\n",
    "    print(\"K\", K.shape)\n",
    "    print(\"focals\", focals.shape)\n",
    "    print(\"centers\", centers.shape)\n",
    "    print(\"c2ws\", c2ws.shape)\n",
    "\n",
    "    ##################################################################### HDRis ####################################################################\n",
    "    list_of_hdris = []\n",
    "    hdri_indices = []\n",
    "    hdris = []\n",
    "    for json_file in json_files:\n",
    "        hdri_fn = json.load(open(json_file))['bg_file']\n",
    "        exr_fn = hdri_fn[:-3] + 'exr'\n",
    "        if exr_fn in list_of_hdris:\n",
    "            hdri_indices.append(list_of_hdris.index(exr_fn))\n",
    "        else:\n",
    "            hdri_folder = './data/HDRis/'\n",
    "            # download hdri\n",
    "            image_url =  'https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/4k/'+exr_fn\n",
    "            response = requests.get(image_url, stream=True, headers={'User-agent': 'Mozilla/5.0'})\n",
    "            with open(hdri_folder+exr_fn, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            # open hdri and append to list\n",
    "            hdri = cv2.cvtColor(cv2.imread(hdri_folder+exr_fn,  cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH), cv2.COLOR_BGR2RGB)\n",
    "            hdris.append(hdri)\n",
    "            list_of_hdris.append(exr_fn)\n",
    "            hdri_indices.append(list_of_hdris.index(exr_fn))\n",
    "            \n",
    "    hdri_indices = np.array(hdri_indices).astype(int)\n",
    "    hdris = np.array(hdris)\n",
    "\n",
    "    ##################################################################### POSE #####################################################################\n",
    "    smpl = SMPL(model_path=smpl_neutral_pkl_file, gender='neutral', joint_mapper=SMPL_JOINT_MAPPER)\n",
    "    bones, betas, root_bones, root_locs = [], [], [], []\n",
    "    for json_file in json_files:\n",
    "        smpl_data = json.load(open(json_file))['skeleton_0']['smpl_data']\n",
    "        joints = np.array(smpl_data['joints'])\n",
    "        verts = np.array(smpl_data['vertices'])\n",
    "        pose = np.array(smpl_data['pose']).reshape(-1,3)[None,...]\n",
    "        beta = np.array(smpl_data['betas'])[None, ...]\n",
    "        scale = smpl_data['scale']\n",
    "        global_orient = np.array(smpl_data['global_orient']).reshape(-1,3)[None,...]\n",
    "        global_trans = np.array(smpl_data['global_trans']).reshape(-1,3)\n",
    "\n",
    "        smpl_output = smpl(betas=torch.Tensor(beta),\n",
    "                           body_pose=torch.Tensor(pose),\n",
    "                           global_orient=torch.Tensor(global_orient),\n",
    "                           pose2rot=True\n",
    "                        )\n",
    "        \n",
    "        root_loc = global_trans/scale\n",
    "\n",
    "        full_pose = np.concatenate((global_orient, pose), axis=1)\n",
    "\n",
    "        bones.append(full_pose)\n",
    "        betas.append(beta)\n",
    "        root_locs.append(root_loc)\n",
    "\n",
    "    bones = np.concatenate(bones, axis=0)\n",
    "    betas = np.concatenate(betas, axis=0)\n",
    "    root_locs = np.concatenate(root_locs, axis=0)\n",
    "    print('bones:',bones.shape)\n",
    "    print('betas:',betas.shape)\n",
    "\n",
    "    #################################################################### REST_POSE #################################################################\n",
    "    betas = torch.DoubleTensor(betas)\n",
    "    dummy = torch.eye(3).view(1, 1, 3, 3).expand(-1, 24, -1, -1)\n",
    "\n",
    "    rest_info = smpl(\n",
    "        betas=betas.mean(0)[None].float(),\n",
    "        body_pose=dummy[:, 1:].float(),\n",
    "        global_orient=dummy[:, :1].float(),\n",
    "        pose2rot=False\n",
    "    )\n",
    "\n",
    "    rest_verts = rest_info.vertices[0].detach().numpy()\n",
    "    rest_pose = rest_info.joints[0]\n",
    "    rest_pose = rest_pose.detach().numpy()\n",
    "    rest_verts -= rest_pose[0]\n",
    "    rest_pose -= rest_pose[0] # center rest pose\n",
    "\n",
    "    ext_scale=1.0\n",
    "    scale_to_ref=False\n",
    "    # scale the rest pose if needed\n",
    "    if scale_to_ref:\n",
    "        ref_pose = smpl_rest_pose * ext_scale\n",
    "        bone_len = calculate_bone_length(rest_pose).mean()\n",
    "        ref_bone_len = calculate_bone_length(ref_pose).mean()\n",
    "        pose_scale = ref_bone_len / bone_len\n",
    "    else:\n",
    "        pose_scale = 1.0\n",
    "    rest_pose = rest_pose * pose_scale\n",
    "    rest_verts = rest_verts * pose_scale\n",
    "\n",
    "    ########################### POSE Pt.2 ###################\n",
    "    \n",
    "    l2ws = np.array([get_smpl_l2ws(bone, rest_pose=rest_pose) for bone in bones])\n",
    "    l2ws[..., :3, -1] += root_locs[:, None]\n",
    "    print('l2ws:',l2ws.shape)\n",
    "    kp3d = l2ws[..., :3, -1]\n",
    "    skts = np.array([np.linalg.inv(l2w) for l2w in l2ws])\n",
    "    print('kp3d:',kp3d.shape)\n",
    "    print('skts:',skts.shape)\n",
    "\n",
    "    ###################################################################### CYLS ######################################################################\n",
    "    cyls = get_kp_bounding_cylinder(\n",
    "        kp3d,\n",
    "        ext_scale=0.001,\n",
    "        skel_type=SMPLSkeleton,\n",
    "        extend_mm=250,\n",
    "        top_expand_ratio=1.00,\n",
    "        bot_expand_ratio=0.25,\n",
    "        head='y'\n",
    "    )\n",
    "\n",
    "    ################################################################## IMAGES, MASKS, BGs ##############################################################\n",
    "\n",
    "    imgs = []\n",
    "    bkgds = []\n",
    "    masks = []\n",
    "    sampling_masks = []\n",
    "    bkgd_masks = []\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        imgs.append(np.asarray(Image.open(img_path))[:,:,:3])\n",
    "\n",
    "    for mask_path in mask_paths:\n",
    "        mask = np.copy(np.asarray(Image.open(mask_path))[:,:,3])\n",
    "        mask[mask < 128] = 0\n",
    "        mask[mask > 128] = 1\n",
    "        kernel = np.ones((11, 11), np.uint8)\n",
    "        sampling_mask = cv2.dilate(mask, kernel=kernel, iterations=2)\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        bkgd_mask = cv2.dilate(mask, kernel=kernel, iterations=2)\n",
    "        masks.append(mask.astype(np.uint8)[..., None])\n",
    "        sampling_masks.append(sampling_mask.astype(np.uint8)[..., None])\n",
    "        bkgd_masks.append(bkgd_mask.astype(np.uint8)[..., None])\n",
    "    \n",
    "    imgs = np.stack(imgs)\n",
    "    print('imgs', imgs.shape)\n",
    "\n",
    "\n",
    "    masks = np.stack(masks)\n",
    "    sampling_masks = np.stack(sampling_masks).astype(np.uint8)\n",
    "    bkgd_masks = np.stack(bkgd_masks).astype(np.uint8)\n",
    "    print('masks', masks.shape)\n",
    "    print('sampling masks', sampling_masks.shape)\n",
    "\n",
    "    bkgds.append(np.max(imgs * (1-bkgd_masks), axis=0))\n",
    "\n",
    "    bkgds = np.stack(bkgds).astype(np.uint8)\n",
    "    print('bkgds', bkgds.shape)\n",
    "\n",
    "    ################################################################### FINAL OUTPUT ##################################################################\n",
    "    data = {\n",
    "        'imgs': np.array(imgs),\n",
    "        'bkgds': np.array(bkgds),\n",
    "        'bkgd_idxs': cam_idxs.astype(int),\n",
    "        'masks': np.array(masks).reshape(-1, H, W, 1),\n",
    "        'sampling_masks': np.array(sampling_masks).reshape(-1, H, W, 1),\n",
    "        'c2ws': c2ws.astype(np.float32),\n",
    "        'img_pose_indices': cam_idxs.astype(int),\n",
    "        'kp_idxs': np.array(kp_idxs).astype(int),\n",
    "        'centers': centers.astype(np.float32),\n",
    "        'focals': focals.astype(np.float32),\n",
    "        'kp3d': kp3d.astype(np.float32),\n",
    "        'betas': betas.numpy().astype(np.float32),\n",
    "        'bones': bones.astype(np.float32),\n",
    "        'skts': skts.astype(np.float32),\n",
    "        'cyls': cyls.astype(np.float32),\n",
    "        'rest_pose': rest_pose.astype(np.float32),\n",
    "        'hdri_indices': hdri_indices,\n",
    "        'hdris': hdris,\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_neutral_pkl_file = './PATH TO SMPL/SMPL_NEUTRAL.pkl'\n",
    "data = process_RANA('./PATH TO RANA/RelightingHumans-release-v0.1/train_p2_p3/subject_01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_h5py(os.path.join(\"./data/RANA/subject_01_train.h5\"), data)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
